# NLP_Paper_Pool
<!-- TABLE OF CONTENTS -->
## Table of Contents
* [Machine Translation](#machine-translation)
* [Machine Translation (Non-Autoregressive)](#machine-translation-non-autoregressive)
* [Knowledge Distillation](#knowledge-distillation)
* [Attention](#attention)

<!-- Machine Translation -->
### Machine Translation
- September 2020: [Softmax Tempering for Training Neural Machine Translation Models](https://arxiv.org/abs/2009.09372)
- September 2020: [CSP: Code-Switching Pre-training for Neural Machine Translation](https://arxiv.org/abs/2009.08088)
- June 2020: [Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff in Machine Translation](https://arxiv.org/abs/2006.10369)

<!-- Machine Translation (Non-Autoregressive)-->
### Machine Translation (Non-Autoregressive)
- April 2020: [Non-Autoregressive Machine Translation with Latent Alignments](https://arxiv.org/abs/2004.07437)

<!-- Knowledge Distillation -->
### Knowledge Distillation
- September 2020: [Weight Distillation: Transferring the Knowledge in Neural Network Parameters](https://arxiv.org/abs/2009.09152)

<!-- Attention -->
### Attention
- September 2020: [Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference](https://arxiv.org/abs/2009.09364)
