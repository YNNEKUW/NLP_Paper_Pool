# NLP_Paper_Pool
<!-- TABLE OF CONTENTS -->
## Table of Contents
* [Machine Translation](#machine-translation)
* [Machine Translation (Non-Autoregressive)](#machine-translation-non-autoregressive)
* [Machine Translation (Low-Resource)](#machine-translation-low-resource)
* [Knowledge Distillation](#knowledge-distillation)
* [Attention](#attention)
* [Transformers](#transformers)
* [Training Tips for Transformers](#training-tips-for-transformers)
  * [Positional Encoding](#positional-encoding)

<!-- Machine Translation -->
### Machine Translation
- September 2020: [Softmax Tempering for Training Neural Machine Translation Models](https://arxiv.org/abs/2009.09372)
- September 2020: [CSP: Code-Switching Pre-training for Neural Machine Translation](https://arxiv.org/abs/2009.08088)
- June 2020: [Deep Encoder, Shallow Decoder: Reevaluating the Speed-Quality Tradeoff in Machine Translation](https://arxiv.org/abs/2006.10369)

<!-- Machine Translation (Non-Autoregressive)-->
### Machine Translation (Non-Autoregressive)
- April 2020: [Non-Autoregressive Machine Translation with Latent Alignments](https://arxiv.org/abs/2004.07437)

<!-- Machine Translation (Low-Resource)-->
### Machine Translation (Low-Resource)
- September 2020: [Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages](https://arxiv.org/abs/2009.11201)

<!-- Knowledge Distillation -->
### Knowledge Distillation
- September 2020: [Contrastive Distillation on Intermediate Representations for Language Model Compression](https://arxiv.org/abs/2009.14167v1)
- September 2020: [Weight Distillation: Transferring the Knowledge in Neural Network Parameters](https://arxiv.org/abs/2009.09152)
- June 2020: [SqueezeBERT: What can computer vision teach NLP about efficient neural networks?](https://arxiv.org/abs/2006.11316)
- February 2020: [BERT-of-Theseus: Compressing BERT by Progressive Module Replacing](https://arxiv.org/abs/2002.02925)

<!-- Attention -->
### Attention
- September 2020: [Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference](https://arxiv.org/abs/2009.09364)

<!-- Transforemrs -->
### Transformers
- April 2020: [Fast and Accurate Deep Bidirectional Language Representations for Unsupervised Learning](https://arxiv.org/abs/2004.08097)

<!-- Traning Tips for Transformers -->
### Training Tips for Transformers
#### Positional Encoding
